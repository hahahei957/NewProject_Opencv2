


'''
加载数据
    五步加载法加载数据
        data.split（）
        shuffle打乱数据
        batch规定每次投喂数据量
        map通过自己定义的预处理数据函数，处理数据集变量格式，调整矩阵维度
        repeat重复投喂次数
构建网络层
    每一层的网络，
        构想好需要的网络层数
        设置每一层的权重也就是张量(矩阵，Variable)大小
        根据每层权重的不同，设置对应的权重
    返回每一层的权重、偏置
构建训练函数
    训练
        得到传入的训练集
        在梯度下降的 with...as tape..中
            根据构想好的网络层，用对应层的权重偏置配置好每一层的方程
            根据需要加入激活函数relu
            配置好全连接层，得到output
            写入想要优化的损失函数loss
                loss函数具体就是，我们的output和真实的训练集的y之间的差距，注意两者都是[b, 10]的形式
                    这里也就是我感觉上面加载数据时，需要先进行batch，确定每次的b的大小，在进行预处理preprocess，从而得到真实训练集中的[b,10]
        调用梯度下降，对于要优化的lose函数进行w1、b1、w2、b2、、、方向的求导
        通过学习率，也就是步长，确定每次每个权重偏置梯度下降的大小
        打印优化好的结果，偏于查看优化进度
    通过测试集，查看训练的权重、偏置对于测试集的拟合效果
        得到传入的测试集
            遍历得到每次投喂的样本
                建立和训练时相同的网络层，并最终通过网络层得到输出的output ==》 [b, 10]
                通过argmax函数，得到每一个样本中的最大值的索引 也就是将 [b, 10] ==> [b] 而[b]中是每一个样本最大值的索引
                将真实值y的one-hot编码[b,10]也通过argmax找到最大值所在位置的索引
                用equal比对两者间的差距，得到最后的比对结果
            得出最后的准确率 total_right/total
    返回 误差loss和准确率
主函数，调度所有内容
    调用加载数据函数，得到db_train和test
    得到初始化所需每层网络层的权重、偏置
    将数据、权重和偏置传给训练函数开始训练
'''



